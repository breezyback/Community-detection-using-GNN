{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWkpRpiQtgXj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.datasets import SNAPDataset\n",
        "from torch_geometric.utils.convert import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "dataset = Planetoid(root='', name='Citeseer')\n",
        "data = dataset[0]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXjlxLU-oqHE"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = to_networkx(dataset[0], to_undirected = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmBl45u-o8VH"
      },
      "outputs": [],
      "source": [
        "from community import community_louvain\n",
        "\n",
        "partition = community_louvain.best_partition(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffEnpGnmpGSF"
      },
      "outputs": [],
      "source": [
        "communities = []\n",
        "y_s = []\n",
        "\n",
        "for part in partition:\n",
        "  y_s.append(partition[part])\n",
        "  if partition[part] not in communities:\n",
        "    communities.append(partition[part])\n",
        "\n",
        "communities.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H77KiJitcY_F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "y = torch.Tensor(y_s)\n",
        "y = y.type(torch.LongTensor)\n",
        "\n",
        "data.y = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biTqtQu7ZtxL"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.transforms import RandomNodeSplit\n",
        "\n",
        "split = \"test_rest\"\n",
        "\n",
        "transform = RandomNodeSplit(split=split, num_val= 0)\n",
        "data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE8VikIpeJ_T"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.transforms import GCNNorm\n",
        "\n",
        "norm = GCNNorm()\n",
        "norm(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShwZdhC5CF1r"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GCN, self).__init__()\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    self.conv1 = GCNConv(dataset.num_features, 16)\n",
        "    self.conv4 = GCNConv(16, 4)\n",
        "    self.dropout = torch.nn.Dropout(p=0.2)\n",
        "    self.conv2 = GCNConv(4, len(communities))\n",
        "    \n",
        "  def forward(self, x, edge_index, edge_weight):\n",
        "    h = self.conv1(x, edge_index, edge_weight)\n",
        "    h = h.relu()\n",
        "    \n",
        "    h = self.conv4(h, edge_index, edge_weight)\n",
        "    h = self.dropout(h)\n",
        "    h = h.relu()\n",
        "\n",
        "    h = self.conv2(h, edge_index, edge_weight)\n",
        "    \n",
        "    out = torch.nn.functional.log_softmax(h, dim=1)\n",
        "    return out, h\n",
        "    \n",
        "model = GCN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iAiiIHRCIXN"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train(data):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  out, h = model(data.x, data.edge_index, data.edge_weight)\n",
        "  loss = criterion(out[data.train_mask], y[data.train_mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss, h\n",
        "\n",
        "def test(data):\n",
        "  model.eval()\n",
        "  out, h = model(data.x, data.edge_index, data.edge_weight)\n",
        "  pred = out.argmax(dim=1)\n",
        "  \n",
        "  test_correct = pred[data.test_mask] == y[data.test_mask]\n",
        "\n",
        "  train_correct = pred[data.train_mask] == y[data.train_mask]\n",
        "  \n",
        "  test_acc = int(test_correct.sum().item()) / int(data.test_mask.sum().item())  \n",
        "\n",
        "  train_acc = int(train_correct.sum().item()) / int(data.train_mask.sum().item())  \n",
        "\n",
        "  return test_acc, train_acc, pred\n",
        "\n",
        "epochs = range(1, 1001)\n",
        "losses = []\n",
        "embeddings = []\n",
        "\n",
        "pred = []\n",
        "Ep = []\n",
        "Test = []\n",
        "Train = []\n",
        "\n",
        "for epoch in epochs:\n",
        "  loss, h = train(data)\n",
        "  losses.append(loss)\n",
        "  embeddings.append(h)\n",
        "\n",
        "  Ep.append(epoch)\n",
        "  pred = []\n",
        "\n",
        "  test_acc, train_acc, pred = test(data)\n",
        "  Train.append(train_acc)\n",
        "  Test.append(test_acc)\n",
        "  print(f\"Epoch: {epoch}\\tTest Accuracy: {test_acc:.4f} \\tTrain Accuracy: {train_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24qXAsreOVIb"
      },
      "outputs": [],
      "source": [
        "p = torch.Tensor.tolist(pred)\n",
        "labels = torch.Tensor.tolist(data.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04IInmfXNpqu",
        "outputId": "8e7d4d9c-174a-4b31-f3a7-11272cc6a28c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "\n",
        "normalized_mutual_info_score(labels, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJYHmZcPPL_L",
        "outputId": "5f8c896a-135a-481c-d7a7-3522a9223e6d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(labels, p, average='micro')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final_GNN_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
